black.list.file.dir=/software/servers/hadoop-2.7.1/etc/hadoop//blacklist.xml
dfs.block.access.key.update.interval=600
dfs.block.access.token.enable=false
dfs.block.access.token.lifetime=600
dfs.block.scanner.volume.bytes.per.second=1048576
dfs.blockreport.initialDelay=0
dfs.blockreport.intervalMsec=21600000
dfs.blockreport.split.threshold=1000000
dfs.blocksize=134217728
dfs.bytes-per-checksum=512
dfs.cachereport.intervalMsec=10000
dfs.checksum.type=CRC32
dfs.client-write-packet-size=65536
dfs.client.block.write.replace-datanode-on-failure.best-effort=false
dfs.client.block.write.replace-datanode-on-failure.enable=true
dfs.client.block.write.replace-datanode-on-failure.policy=DEFAULT
dfs.client.block.write.retries=3
dfs.client.cached.conn.retry=3
dfs.client.context=default
dfs.client.datanode-restart.timeout=30
dfs.client.domain.socket.data.traffic=false
dfs.client.failover.connection.retries.on.timeouts=0
dfs.client.failover.connection.retries=0
dfs.client.failover.max.attempts=15
dfs.client.failover.sleep.base.millis=500
dfs.client.failover.sleep.max.millis=15000
dfs.client.file-block-storage-locations.num-threads=10
dfs.client.file-block-storage-locations.timeout.millis=60000
dfs.client.https.keystore.resource=ssl-client.xml
dfs.client.https.need-auth=false
dfs.client.mmap.cache.size=256
dfs.client.mmap.cache.timeout.ms=3600000
dfs.client.mmap.enabled=true
dfs.client.mmap.retry.timeout.ms=300000
dfs.client.read.shortcircuit.skip.checksum=false
dfs.client.read.shortcircuit.streams.cache.expiry.ms=300000
dfs.client.read.shortcircuit.streams.cache.size=1024
dfs.client.read.shortcircuit=true
dfs.client.short.circuit.replica.stale.threshold.ms=1800000
dfs.client.slow.io.warning.threshold.ms=30000
dfs.client.socket-timeout=180000
dfs.client.use.datanode.hostname=false
dfs.client.use.legacy.blockreader.local=false
dfs.client.write.exclude.nodes.cache.expiry.interval.millis=600000
dfs.cluster.administrators=*
dfs.cluster.id=10k
dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction=0.75f
dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold=10737418240
dfs.datanode.balance.bandwidthPerSec=10485760
dfs.datanode.block-pinning.enabled=false
dfs.datanode.block.id.layout.upgrade.threads=12
dfs.datanode.cache.revocation.polling.ms=500
dfs.datanode.cache.revocation.timeout.ms=900000
dfs.datanode.cached-dfsused.check.interval.ms=14400000
dfs.datanode.data.dir.perm=700
dfs.datanode.data.dir=/data0/dfs,/data1/dfs,/data2/dfs,/data3/dfs,/data4/dfs,/data5/dfs,/data6/dfs,/data7/dfs,/data8/dfs,/data9/dfs,/data10/dfs,/data11/dfs
dfs.datanode.directoryscan.interval=21600
dfs.datanode.directoryscan.threads=6
dfs.datanode.directoryscan.throttle.limit.ms.per.sec=0
dfs.datanode.dns.interface=default
dfs.datanode.dns.nameserver=default
dfs.datanode.drop.cache.behind.reads=false
dfs.datanode.drop.cache.behind.writes=false
dfs.datanode.du.reserved=307374182400
dfs.datanode.failed.volumes.tolerated=3
dfs.datanode.fsdatasetcache.max.threads.per.volume=4
dfs.datanode.handler.count=30
dfs.datanode.hdfs-blocks-metadata.enabled=true
dfs.datanode.kerberos.principal=hdfs/_HOST@HADOOP.CHINATELECOM.CN
dfs.datanode.keytab.file=/etc/hadoop/conf/hdfs.keytab
dfs.datanode.max.locked.memory=0
dfs.datanode.max.transfer.threads=65536
dfs.datanode.readahead.bytes=4194304
dfs.datanode.scan.period.hours=504
dfs.datanode.shared.file.descriptor.paths=/dev/shm,/tmp
dfs.datanode.slow.io.warning.threshold.ms=300
dfs.datanode.sync.behind.writes=false
dfs.datanode.use.datanode.hostname=false
dfs.default.chunk.view.size=32768
dfs.domain.socket.path=/var/lib/hadoop-hdfs/dn_socket
dfs.encrypt.data.transfer.cipher.key.bitlength=128
dfs.encrypt.data.transfer=false
dfs.erp.auth-method=simple
dfs.erp.authorization=false
dfs.ha.automatic-failover.enabled=true
dfs.ha.fencing.methods=sshfence
dfs.ha.fencing.ssh.connect-timeout=30000
dfs.ha.fencing.ssh.private-key-files=/home/hadp/.ssh/id_rsa
dfs.ha.log-roll.period=120
dfs.ha.namenodes.ns2=nn1,nn2
dfs.ha.namenodes.ns3=nn1,nn2
dfs.ha.namenodes.ns4=nn1,nn2
dfs.ha.namenodes.ns=nn1,nn2
dfs.ha.tail-edits.period=60
dfs.heartbeat.interval=3
dfs.hosts.exclude=/software/servers/hadoop-2.7.1/etc/hadoop/hosts/exclude_datanode_hosts
dfs.hosts=/software/servers/hadoop-2.7.1/etc/hadoop/hosts/datanode_hosts
dfs.http.policy=HTTP_ONLY
dfs.https.server.keystore.resource=ssl-server.xml
dfs.image.compress=false
dfs.image.compression.codec=org.apache.hadoop.io.compress.DefaultCodec
dfs.image.transfer.bandwidthPerSec=41943040
dfs.image.transfer.chunksize=65536
dfs.image.transfer.timeout=1800000
dfs.journalnode.edits.dir=/data0/journal/data
dfs.journalnode.kerberos.internal.spnego.principal=HTTP/_HOST@HADOOP.CHINATELECOM.CN
dfs.journalnode.kerberos.principal=hdfs/_HOST@HADOOP.CHINATELECOM.CN
dfs.journalnode.keytab.file=/etc/hadoop/conf/hdfs.keytab
dfs.lock.suppress.warning.interval=10s
dfs.namenode.accesstime.precision=3600000
dfs.namenode.acls.enabled=false
dfs.namenode.audit.loggers=default
dfs.namenode.avoid.read.stale.datanode=false
dfs.namenode.avoid.write.stale.datanode=false
dfs.namenode.blocks.per.postponedblocks.rescan=10000
dfs.namenode.checkpoint.check.period=60
dfs.namenode.checkpoint.edits.dir=${dfs.namenode.checkpoint.dir}
dfs.namenode.checkpoint.max-retries=3
dfs.namenode.checkpoint.period=3600
dfs.namenode.checkpoint.txns=10000000
dfs.namenode.datanode.registration.ip-hostname-check=true
dfs.namenode.decommission.blocks.per.interval=500000
dfs.namenode.decommission.interval=30
dfs.namenode.decommission.max.concurrent.tracked.nodes=100
dfs.namenode.delegation.key.update-interval=86400000
dfs.namenode.delegation.token.max-lifetime=604800000
dfs.namenode.delegation.token.renew-interval=86400000
dfs.namenode.edit.log.autoroll.check.interval.ms=300000
dfs.namenode.edit.log.autoroll.multiplier.threshold=2.0
dfs.namenode.edits.dir=${dfs.namenode.name.dir}
dfs.namenode.edits.journal-plugin.qjournal=org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager
dfs.namenode.edits.noeditlogchannelflush=false
dfs.namenode.enable.retrycache=false
dfs.namenode.fs-limits.max-blocks-per-file=1048576
dfs.namenode.fs-limits.max-component-length=255
dfs.namenode.fs-limits.max-directory-items=1048576
dfs.namenode.fs-limits.max-xattr-size=16384
dfs.namenode.fs-limits.max-xattrs-per-inode=32
dfs.namenode.fs-limits.min-block-size=1048576
dfs.namenode.fslock.fair=true
dfs.namenode.handler.count=140
dfs.namenode.heartbeat.recheck-interval=300000
dfs.namenode.inode.attributes.provider.class=com.jd.bdp.authorization.hadoop.JdhHdfsAuthorizer
dfs.namenode.inotify.max.events.per.rpc=1000
dfs.namenode.invalidate.work.pct.per.iteration=0.32f
dfs.namenode.kerberos.internal.spnego.principal=HTTP/_HOST@HADOOP.CHINATELECOM.CN
dfs.namenode.kerberos.principal.pattern=*
dfs.namenode.kerberos.principal=hdfs/_HOST@HADOOP.CHINATELECOM.CN
dfs.namenode.keytab.file=/etc/hadoop/conf/hdfs.keytab
dfs.namenode.lazypersist.file.scrub.interval.sec=300
dfs.namenode.list.cache.directives.num.responses=100
dfs.namenode.list.cache.pools.num.responses=100
dfs.namenode.list.encryption.zones.num.responses=100
dfs.namenode.lock.detailed-metrics.enabled=false
dfs.namenode.max.extra.edits.segments.retained=10000
dfs.namenode.max.objects=0
dfs.namenode.name.dir.restore=false
dfs.namenode.num.checkpoints.retained=2
dfs.namenode.num.extra.edits.retained=1000000
dfs.namenode.path.based.cache.block.map.allocation.percent=0.25
dfs.namenode.path.based.cache.refresh.interval.ms=30000
dfs.namenode.path.based.cache.retry.interval.ms=30000
dfs.namenode.reject-unresolved-dn-topology-mapping=false
dfs.namenode.replication.considerLoad=true
dfs.namenode.replication.interval=3
dfs.namenode.replication.min=1
dfs.namenode.replication.work.multiplier.per.iteration=2
dfs.namenode.resource.check.interval=5000
dfs.namenode.resource.checked.volumes.minimum=1
dfs.namenode.resource.du.reserved=104857600
dfs.namenode.retrycache.expirytime.millis=600000
dfs.namenode.retrycache.heap.percent=0.03f
dfs.namenode.safemode.extension=30000
dfs.namenode.safemode.min.datanodes=0
dfs.namenode.safemode.threshold-pct=0.999f
dfs.namenode.service.handler.count=140
dfs.namenode.stale.datanode.interval=30000
dfs.namenode.startup.delay.block.deletion.sec=0
dfs.namenode.support.allow.format=true
dfs.namenode.top.enabled=true
dfs.namenode.top.num.users=10
dfs.namenode.top.window.num.buckets=10
dfs.namenode.top.windows.minutes=1,5,25
dfs.namenode.write.stale.datanode.ratio=0.5f
dfs.namenode.xattrs.enabled=true
dfs.nameservices=ns1,ns2,ns3,ns4,ns5,ns6,ns7,ns8,ns9,ns10,ns11,ns12,ns13,ns14,ns15,ns16
dfs.permissions.enabled=true
dfs.permissions.superusergroup=supergroup
dfs.replication.max=512
dfs.replication=3
dfs.secondary.namenode.kerberos.internal.spnego.principal=HTTP/_HOST@HADOOP.CHINATELECOM.CN
dfs.secondary.namenode.kerberos.principal=hdfs/_HOST@HADOOP.CHINATELECOM.CN
dfs.secondary.namenode.keytab.file=/etc/hadoop/conf/hdfs.keytab
dfs.short.circuit.shared.memory.watcher.interrupt.check.ms=60000
dfs.storage.policy.enabled=true
dfs.stream-buffer-size=4096
dfs.user.home.dir.prefix=/user
dfs.webhdfs.enabled=false
dfs.webhdfs.user.provider.user.pattern=^[A-Za-z_][A-Za-z0-9._-]*[$]?$
file.blocksize=67108864
file.bytes-per-checksum=512
file.client-write-packet-size=65536
file.replication=1
file.stream-buffer-size=4096
fs.AbstractFileSystem.file.impl=org.apache.hadoop.fs.local.LocalFs
fs.AbstractFileSystem.ftp.impl=org.apache.hadoop.fs.ftp.FtpFs
fs.AbstractFileSystem.har.impl=org.apache.hadoop.fs.HarFs
fs.AbstractFileSystem.hdfs.impl=org.apache.hadoop.fs.Hdfs
fs.AbstractFileSystem.viewfs.impl=org.apache.hadoop.fs.viewfs.ViewFs
fs.automatic.close=true
fs.client.resolve.remote.symlinks=true
fs.defaultFS=hdfs://ns10
fs.df.interval=60000
fs.du.interval=86400000
fs.du.timer.hour=19
fs.ftp.host.port=21
fs.ftp.host=0.0.0.0
fs.getspaceused.jitterMillis=3600000
fs.har.impl.disable.cache=true
fs.inmemory.size.mb=512
fs.permissions.umask-mode=022
fs.s3.block.size=67108864
fs.s3.buffer.dir=${hadoop.tmp.dir}/s3
fs.s3.maxRetries=4
fs.s3.sleepTimeSeconds=10
fs.s3a.attempts.maximum=10
fs.s3a.buffer.dir=${hadoop.tmp.dir}/s3a
fs.s3a.connection.establish.timeout=5000
fs.s3a.connection.maximum=15
fs.s3a.connection.ssl.enabled=true
fs.s3a.connection.timeout=50000
fs.s3a.fast.buffer.size=1048576
fs.s3a.fast.upload=false
fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
fs.s3a.max.total.tasks=1000
fs.s3a.multipart.purge.age=86400
fs.s3a.multipart.purge=false
fs.s3a.multipart.size=104857600
fs.s3a.multipart.threshold=2147483647
fs.s3a.paging.maximum=5000
fs.s3a.threads.core=15
fs.s3a.threads.keepalivetime=60
fs.s3a.threads.max=256
fs.s3n.block.size=67108864
fs.s3n.multipart.copy.block.size=5368709120
fs.s3n.multipart.uploads.block.size=67108864
fs.s3n.multipart.uploads.enabled=false
fs.swift.impl=org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem
fs.trash.checkpoint.interval=0
fs.trash.interval=1440
ftp.blocksize=67108864
ftp.bytes-per-checksum=512
ftp.client-write-packet-size=65536
ftp.replication=3
ftp.stream-buffer-size=4096
ha.failover-controller.cli-check.rpc-timeout.ms=20000
ha.failover-controller.graceful-fence.connection.retries=1
ha.failover-controller.graceful-fence.rpc-timeout.ms=160000
ha.failover-controller.new-active.rpc-timeout.ms=360000
ha.health-monitor.check-interval.ms=1000
ha.health-monitor.connect-retry-interval.ms=1000
ha.health-monitor.rpc-timeout.ms=180000
ha.health-monitor.sleep-after-disconnect.ms=1000
ha.zookeeper.acl=world:anyone:rwcda
ha.zookeeper.parent-znode=/10k-hadoop-ha
ha.zookeeper.session-timeout.ms=5000
hadoop.common.configuration.version=0.23.0
hadoop.fuse.connection.timeout=300
hadoop.fuse.timer.period=5
hadoop.hdfs.configuration.version=1
hadoop.http.authentication.kerberos.keytab=${user.home}/hadoop.keytab
hadoop.http.authentication.kerberos.principal=HTTP/_HOST@LOCALHOST
hadoop.http.authentication.signature.secret.file=${user.home}/hadoop-http-auth-signature-secret
hadoop.http.authentication.simple.anonymous.allowed=true
hadoop.http.authentication.token.validity=36000
hadoop.http.authentication.type=simple
hadoop.http.filter.initializers=org.apache.hadoop.http.lib.StaticUserWebFilter
hadoop.http.logs.enabled=true
hadoop.http.staticuser.user=dr.who
hadoop.jetty.logs.serve.aliases=true
hadoop.kerberos.kinit.command=/usr/bin/kinit
hadoop.kerberos.min.seconds.before.relogin=60
hadoop.proxyuser.HTTP.groups=*
hadoop.proxyuser.HTTP.hosts=*
hadoop.proxyuser.hbase.groups=*
hadoop.proxyuser.hbase.hosts=*
hadoop.proxyuser.hive.groups=*
hadoop.proxyuser.hive.hosts=*
hadoop.proxyuser.httpfs.groups=*
hadoop.proxyuser.httpfs.hosts=*
hadoop.proxyuser.hue.groups=*
hadoop.proxyuser.hue.hosts=*
hadoop.proxyuser.oozie.groups=*
hadoop.proxyuser.oozie.hosts=*
hadoop.registry.jaas.context=Client
hadoop.registry.rm.enabled=false
hadoop.registry.secure=false
hadoop.registry.zk.connection.timeout.ms=15000
hadoop.registry.zk.retry.ceiling.ms=60000
hadoop.registry.zk.retry.interval.ms=1000
hadoop.registry.zk.retry.times=5
hadoop.registry.zk.root=/registry
hadoop.registry.zk.session.timeout.ms=60000
hadoop.rpc.protection=authentication
hadoop.rpc.socket.factory.class.default=org.apache.hadoop.net.StandardSocketFactory
hadoop.security.authentication=simple
hadoop.security.authorization=true
hadoop.security.crypto.buffer.size=8192
hadoop.security.crypto.cipher.suite=AES/CTR/NoPadding
hadoop.security.crypto.codec.classes.aes.ctr.nopadding=org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec,org.apache.hadoop.crypto.JceAesCtrCryptoCodec
hadoop.security.group.mapping.ldap.directory.search.timeout=10000
hadoop.security.group.mapping.ldap.posix.attr.gid.name=gidNumber
hadoop.security.group.mapping.ldap.posix.attr.uid.name=uidNumber
hadoop.security.group.mapping.ldap.search.attr.group.name=cn
hadoop.security.group.mapping.ldap.search.attr.member=member
hadoop.security.group.mapping.ldap.search.filter.group=(objectClass=group)
hadoop.security.group.mapping.ldap.search.filter.user=?
hadoop.security.group.mapping.ldap.ssl=false
hadoop.security.group.mapping.path=/software/servers/hadoop-2.7.1/etc/hadoop/hadoop-ugmappings.xml
hadoop.security.group.mapping=org.apache.hadoop.security.ErpGroupsMapping
hadoop.security.groups.cache.secs=300
hadoop.security.groups.cache.warn.after.ms=5000
hadoop.security.groups.negative-cache.secs=30
hadoop.security.instrumentation.requires.admin=false
hadoop.security.java.secure.random.algorithm=SHA1PRNG
hadoop.security.kms.client.authentication.retry-count=1
hadoop.security.kms.client.encrypted.key.cache.expiry=43200000
hadoop.security.kms.client.encrypted.key.cache.low-watermark=0.3f
hadoop.security.kms.client.encrypted.key.cache.num.refill.threads=2
hadoop.security.kms.client.encrypted.key.cache.size=500
hadoop.security.random.device.file.path=/dev/urandom
hadoop.security.ugdap.full.interface=http://ugdap.jd.com/10knew/api/queryUsers.json?token=f45c36ccf2eb661a38d588b6373c4688
hadoop.security.ugdap.short.interface=http://ugdap.jd.com/10knew/api/queryIncrementUsers.json?token=f45c36ccf2eb661a38d588b6373c4688&versionNum=
hadoop.security.uid.cache.secs=14400
hadoop.ssl.client.conf=ssl-client.xml
hadoop.ssl.enabled.protocols=TLSv1
hadoop.ssl.enabled=false
hadoop.ssl.hostname.verifier=DEFAULT
hadoop.ssl.keystores.factory.class=org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory
hadoop.ssl.require.client.cert=false
hadoop.ssl.server.conf=ssl-server.xml
hadoop.tmp.dir=/data0/hadoop_tmp
hadoop.user.group.static.mapping.overrides=dr.who=;
hadoop.util.hash.type=murmur
hadoop.work.around.non.threadsafe.getpwuid=false
hbase.client.retries.number=3
hbase.table.namespace=jdh_10k_new
io.compression.codec.bzip2.library=system-native
io.compression.codec.lzo.class=com.hadoop.compression.lzo.LzoCodec
io.compression.codecs=org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.BZip2Codec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.SnappyCodec
io.file.buffer.size=131072
io.map.index.interval=128
io.map.index.skip=0
io.mapfile.bloom.error.rate=0.005
io.mapfile.bloom.size=1048576
io.native.lib.available=true
io.seqfile.compress.blocksize=1000000
io.seqfile.lazydecompress=true
io.seqfile.local.dir=${hadoop.tmp.dir}/io/local
io.seqfile.sorter.recordlimit=1000000
io.serializations=org.apache.hadoop.io.serializer.WritableSerialization,org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization,org.apache.hadoop.io.serializer.avro.AvroReflectSerialization
io.skip.checksum.errors=false
ipc.8020.callqueue.impl=org.apache.hadoop.ipc.FairCallQueue
ipc.8020.faircallqueue.decay-scheduler.period-ms=60000
ipc.client.connect.max.retries.on.timeouts=45
ipc.client.connect.max.retries=10
ipc.client.connect.retry.interval=1000
ipc.client.connect.timeout=20000
ipc.client.connection.maxidletime=10000
ipc.client.fallback-to-simple-auth-allowed=false
ipc.client.idlethreshold=4000
ipc.client.kill.max=10
ipc.server.listen.queue.size=128
ipc.server.max.connections=0
map.sort.class=org.apache.hadoop.util.QuickSort
mapreduce.am.max-attempts=5
mapreduce.app-submission.cross-platform=false
mapreduce.client.completion.pollinterval=5000
mapreduce.client.genericoptionsparser.used=true
mapreduce.client.output.filter=FAILED
mapreduce.client.progressmonitor.pollinterval=1000
mapreduce.client.submit.file.replication=10
mapreduce.cluster.acls.enabled=false
mapreduce.cluster.local.dir=${hadoop.tmp.dir}/mapred/local
mapreduce.cluster.temp.dir=${hadoop.tmp.dir}/mapred/temp
mapreduce.fileoutputcommitter.algorithm.version=1
mapreduce.framework.name=yarn
mapreduce.ifile.readahead.bytes=4194304
mapreduce.ifile.readahead=true
mapreduce.input.fileinputformat.list-status.num-threads=1
mapreduce.input.fileinputformat.split.maxsize=134217728
mapreduce.input.fileinputformat.split.minsize=134217728
mapreduce.input.lineinputformat.linespermap=1
mapreduce.job.acl-modify-job= 
mapreduce.job.acl-view-job= 
mapreduce.job.classloader=false
mapreduce.job.committer.setup.cleanup.needed=true
mapreduce.job.complete.cancel.delegation.tokens=true
mapreduce.job.counters.max=200
mapreduce.job.emit-timeline-data=false
mapreduce.job.end-notification.max.attempts=5
mapreduce.job.end-notification.max.retry.interval=5000
mapreduce.job.end-notification.retry.attempts=0
mapreduce.job.end-notification.retry.interval=1000
mapreduce.job.hdfs-servers=${fs.defaultFS}
mapreduce.job.heap.memory-mb.ratio=0.8
mapreduce.job.jvm.numtasks=5
mapreduce.job.map.output.collector.class=org.apache.hadoop.mapred.MapTask$MapOutputBuffer
mapreduce.job.maps=2
mapreduce.job.max.split.locations=500
mapreduce.job.maxtaskfailures.per.tracker=3
mapreduce.job.queuename=default
mapreduce.job.reduce.shuffle.consumer.plugin.class=org.apache.hadoop.mapreduce.task.reduce.Shuffle
mapreduce.job.reduce.slowstart.completedmaps=0.3
mapreduce.job.reducer.preempt.delay.sec=0
mapreduce.job.reducer.unconditional-preempt.delay.sec=300
mapreduce.job.reduces=1
mapreduce.job.relax.locality=false
mapreduce.job.running.map.limit=0
mapreduce.job.running.reduce.limit=0
mapreduce.job.speculative.minimum-allowed-tasks=10
mapreduce.job.speculative.retry-after-no-speculate=1000
mapreduce.job.speculative.retry-after-speculate=15000
mapreduce.job.speculative.slowtaskthreshold=1.0
mapreduce.job.speculative.speculative-cap-running-tasks=0.1
mapreduce.job.speculative.speculative-cap-total-tasks=0.01
mapreduce.job.split.metainfo.maxsize=10000000
mapreduce.job.token.tracking.ids.enabled=false
mapreduce.job.ubertask.enable=false
mapreduce.job.ubertask.maxmaps=9
mapreduce.job.ubertask.maxreduces=1
mapreduce.job.userlog.retain.hours=24
mapreduce.jobhistory.admin.acl=*
mapreduce.jobhistory.cleaner.enable=true
mapreduce.jobhistory.cleaner.interval-ms=86400000
mapreduce.jobhistory.client.thread-count=10
mapreduce.jobhistory.datestring.cache.size=200000
mapreduce.jobhistory.done-dir=/history-yarn/done
mapreduce.jobhistory.http.policy=HTTP_ONLY
mapreduce.jobhistory.intermediate-done-dir=${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate
mapreduce.jobhistory.joblist.cache.size=10000
mapreduce.jobhistory.keytab=/etc/security/keytab/jhs.service.keytab
mapreduce.jobhistory.loadedjobs.cache.size=5
mapreduce.jobhistory.max-age-ms=604800000
mapreduce.jobhistory.minicluster.fixed.ports=false
mapreduce.jobhistory.move.interval-ms=180000
mapreduce.jobhistory.move.thread-count=3
mapreduce.jobhistory.principal=mapred/_HOST@HADOOP.CHINATELECOM.CN
mapreduce.jobhistory.recovery.enable=false
mapreduce.jobhistory.recovery.store.class=org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService
mapreduce.jobhistory.recovery.store.fs.uri=${hadoop.tmp.dir}/mapred/history/recoverystore
mapreduce.jobhistory.recovery.store.leveldb.path=${hadoop.tmp.dir}/mapred/history/recoverystore
mapreduce.jobtracker.address=local
mapreduce.jobtracker.expire.trackers.interval=600000
mapreduce.jobtracker.handler.count=10
mapreduce.jobtracker.heartbeats.in.second=100
mapreduce.jobtracker.instrumentation=org.apache.hadoop.mapred.JobTrackerMetricsInst
mapreduce.jobtracker.jobhistory.block.size=3145728
mapreduce.jobtracker.jobhistory.lru.cache.size=5
mapreduce.jobtracker.jobhistory.task.numberprogresssplits=12
mapreduce.jobtracker.maxtasks.perjob=-1
mapreduce.jobtracker.persist.jobstatus.active=true
mapreduce.jobtracker.persist.jobstatus.dir=/jobtracker/jobsInfo
mapreduce.jobtracker.persist.jobstatus.hours=1
mapreduce.jobtracker.restart.recover=false
mapreduce.jobtracker.retiredjobs.cache.size=1000
mapreduce.jobtracker.staging.root.dir=${hadoop.tmp.dir}/mapred/staging
mapreduce.jobtracker.system.dir=${hadoop.tmp.dir}/mapred/system
mapreduce.jobtracker.taskcache.levels=2
mapreduce.jobtracker.taskscheduler=org.apache.hadoop.mapred.JobQueueTaskScheduler
mapreduce.jobtracker.tasktracker.maxblacklists=4
mapreduce.local.clientfactory.class.name=org.apache.hadoop.mapred.LocalClientFactory
mapreduce.map.cpu.vcores=1
mapreduce.map.gpu.cores=0
mapreduce.map.java.opts=-Xmx1536M
mapreduce.map.log.level=INFO
mapreduce.map.maxattempts=4
mapreduce.map.memory.mb=2048
mapreduce.map.output.compress.codec=com.hadoop.compression.lzo.LzoCodec
mapreduce.map.output.compress=true
mapreduce.map.skip.maxrecords=0
mapreduce.map.skip.proc.count.autoincr=true
mapreduce.map.sort.spill.percent=0.80
mapreduce.map.speculative=true
mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec
mapreduce.output.fileoutputformat.compress.type=RECORD
mapreduce.output.fileoutputformat.compress=false
mapreduce.reduce.cpu.vcores=1
mapreduce.reduce.gpu.cores=0
mapreduce.reduce.input.buffer.percent=0.0
mapreduce.reduce.java.opts=-Xmx3072M
mapreduce.reduce.log.level=INFO
mapreduce.reduce.markreset.buffer.percent=0.0
mapreduce.reduce.maxattempts=4
mapreduce.reduce.memory.mb=4096
mapreduce.reduce.merge.inmem.threshold=1000
mapreduce.reduce.shuffle.connect.timeout=180000
mapreduce.reduce.shuffle.fetch.retry.enabled=${yarn.nodemanager.recovery.enabled}
mapreduce.reduce.shuffle.fetch.retry.interval-ms=1000
mapreduce.reduce.shuffle.fetch.retry.timeout-ms=30000
mapreduce.reduce.shuffle.input.buffer.percent=0.70
mapreduce.reduce.shuffle.memory.limit.percent=0.25
mapreduce.reduce.shuffle.merge.percent=0.66
mapreduce.reduce.shuffle.parallelcopies=50
mapreduce.reduce.shuffle.read.timeout=180000
mapreduce.reduce.shuffle.retry-delay.max.ms=60000
mapreduce.reduce.skip.maxgroups=0
mapreduce.reduce.skip.proc.count.autoincr=true
mapreduce.reduce.speculative=true
mapreduce.shuffle.connection-keep-alive.enable=false
mapreduce.shuffle.connection-keep-alive.timeout=5
mapreduce.shuffle.max.connections=0
mapreduce.shuffle.max.threads=0
mapreduce.shuffle.port=13562
mapreduce.shuffle.ssl.enabled=false
mapreduce.shuffle.ssl.file.buffer.size=65536
mapreduce.shuffle.transfer.buffer.size=131072
mapreduce.task.combine.progress.records=10000
mapreduce.task.files.preserve.failedtasks=false
mapreduce.task.io.sort.factor=100
mapreduce.task.io.sort.mb=512
mapreduce.task.merge.progress.records=10000
mapreduce.task.profile.map.params=${mapreduce.task.profile.params}
mapreduce.task.profile.maps=0-2
mapreduce.task.profile.reduce.params=${mapreduce.task.profile.params}
mapreduce.task.profile.reduces=0-2
mapreduce.task.profile=false
mapreduce.task.skip.start.attempts=2
mapreduce.task.timeout=960000
mapreduce.task.userlog.limit.kb=0
mapreduce.tasktracker.dns.interface=default
mapreduce.tasktracker.dns.nameserver=default
mapreduce.tasktracker.healthchecker.interval=60000
mapreduce.tasktracker.healthchecker.script.timeout=600000
mapreduce.tasktracker.http.threads=40
mapreduce.tasktracker.indexcache.mb=10
mapreduce.tasktracker.instrumentation=org.apache.hadoop.mapred.TaskTrackerMetricsInst
mapreduce.tasktracker.local.dir.minspacekill=0
mapreduce.tasktracker.local.dir.minspacestart=0
mapreduce.tasktracker.map.tasks.maximum=2
mapreduce.tasktracker.outofband.heartbeat=false
mapreduce.tasktracker.reduce.tasks.maximum=2
mapreduce.tasktracker.taskcontroller=org.apache.hadoop.mapred.DefaultTaskController
mapreduce.tasktracker.taskmemorymanager.monitoringinterval=5000
mapreduce.tasktracker.tasks.sleeptimebeforesigkill=5000
net.topology.impl=org.apache.hadoop.net.NetworkTopology
net.topology.node.switch.mapping.impl=org.apache.hadoop.net.ScriptBasedMapping
net.topology.script.file.name=/etc/hadoop/conf/RackAware.py
net.topology.script.number.args=100
nfs.allow.insecure.ports=true
nfs.dump.dir=/tmp/.hdfs-nfs
nfs.exports.allowed.hosts=* rw
nfs.mountd.port=4242
nfs.rtmax=1048576
nfs.server.port=2049
nfs.wtmax=1048576
rpc.engine.org.apache.hadoop.ha.protocolPB.HAServiceProtocolPB=org.apache.hadoop.ipc.ProtobufRpcEngine
rpc.engine.org.apache.hadoop.ipc.ProtocolMetaInfoPB=org.apache.hadoop.ipc.ProtobufRpcEngine
rpc.engine.org.apache.hadoop.yarn.api.ApplicationClientProtocolPB=org.apache.hadoop.ipc.ProtobufRpcEngine
rpc.engine.org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB=org.apache.hadoop.ipc.ProtobufRpcEngine
rpc.engine.org.apache.hadoop.yarn.server.api.ResourceTrackerPB=org.apache.hadoop.ipc.ProtobufRpcEngine
rpc.metrics.quantile.enable=false
s3.blocksize=67108864
s3.bytes-per-checksum=512
s3.client-write-packet-size=65536
s3.replication=3
s3.stream-buffer-size=4096
s3native.blocksize=67108864
s3native.bytes-per-checksum=512
s3native.client-write-packet-size=65536
s3native.replication=3
s3native.stream-buffer-size=4096
security.admin.operations.protocol.acl=*
security.applicationclient.protocol.acl=*
security.applicationhistory.protocol.acl=*
security.applicationmaster.protocol.acl=*
security.client.datanode.protocol.acl=*
security.client.protocol.acl=*
security.containermanagement.protocol.acl=*
security.datanode.protocol.acl=*
security.ha.service.protocol.acl=*
security.inter.datanode.protocol.acl=*
security.job.client.protocol.acl=*
security.job.task.protocol.acl=*
security.mrhs.client.protocol.acl=*
security.namenode.protocol.acl=*
security.qjournal.service.protocol.acl=*
security.refresh.policy.protocol.acl=*
security.refresh.user.mappings.protocol.acl=*
security.resourcelocalizer.protocol.acl=*
security.resourcemanager-administration.protocol.acl=*
security.resourcetracker.protocol.acl=*
security.zkfc.protocol.acl=*
tfile.fs.input.buffer.size=262144
tfile.fs.output.buffer.size=262144
tfile.io.chunk.size=1048576
white.list.enable=true
white.list.file.dir=/software/servers/hadoop-2.7.1/etc/hadoop//whitelist.xml
yarn.acl.enable=true
yarn.admin.acl=*
yarn.am.liveness-monitor.expiry-interval-ms=600000
yarn.app.mapreduce.am.command-opts=-Xmx1024m
yarn.app.mapreduce.am.container.log.backups=0
yarn.app.mapreduce.am.container.log.limit.kb=0
yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size=10
yarn.app.mapreduce.am.hard-kill-timeout-ms=10000
yarn.app.mapreduce.am.job.committer.cancel-timeout=60000
yarn.app.mapreduce.am.job.committer.commit-window=10000
yarn.app.mapreduce.am.job.recovery.enable=false
yarn.app.mapreduce.am.job.task.listener.thread-count=30
yarn.app.mapreduce.am.resource.cpu-vcores=1
yarn.app.mapreduce.am.resource.gpu-cores=0
yarn.app.mapreduce.am.resource.mb=1536
yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms=1000
yarn.app.mapreduce.am.staging-dir=/yarn/staging
yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts=3
yarn.app.mapreduce.client-am.ipc.max-retries=3
yarn.app.mapreduce.client.job.max-retries=0
yarn.app.mapreduce.client.job.retry-interval=2000
yarn.app.mapreduce.client.max-retries=3
yarn.app.mapreduce.shuffle.log.backups=0
yarn.app.mapreduce.shuffle.log.limit.kb=0
yarn.app.mapreduce.shuffle.log.separate=true
yarn.app.mapreduce.task.container.log.backups=0
yarn.application.classpath=$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/share/hadoop/common/*,$HADOOP_COMMON_HOME/share/hadoop/common/lib/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,$HADOOP_YARN_HOME/share/hadoop/yarn/*,$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*
yarn.client.application-client-protocol.poll-interval-ms=200
yarn.client.failover-proxy-provider=org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider
yarn.client.failover-retries-on-socket-timeouts=0
yarn.client.failover-retries=0
yarn.client.max-cached-nodemanagers-proxies=0
yarn.client.nodemanager-client-async.thread-pool-max-size=500
yarn.client.nodemanager-connect.max-wait-ms=180000
yarn.client.nodemanager-connect.retry-interval-ms=10000
yarn.dispatcher.exit-on-error=true
yarn.federation.cache-ttl.secs=300
yarn.federation.enabled=false
yarn.federation.state-store.class=org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore
yarn.federation.subcluster-resolver.class=org.apache.hadoop.yarn.server.federation.resolver.DefaultSubClusterResolverImpl
yarn.http.policy=HTTP_ONLY
yarn.ipc.rpc.class=org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
yarn.log-aggregation-enable=true
yarn.log-aggregation.retain-check-interval-seconds=86400
yarn.log-aggregation.retain-seconds=864000
yarn.nm.liveness-monitor.expiry-interval-ms=300000
yarn.node-labels.enabled=true
yarn.nodemanager.admin-env=MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX
yarn.nodemanager.amrmproxy.client.thread-count=25
yarn.nodemanager.amrmproxy.enabled=false
yarn.nodemanager.amrmproxy.interceptor-class.pipeline=org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor
yarn.nodemanager.aux-services.mapreduce_shuffle.class=org.apache.hadoop.mapred.ShuffleHandler
yarn.nodemanager.aux-services.spark_shuffle.class=org.apache.spark.network.yarn.YarnShuffleService
yarn.nodemanager.aux-services=mapreduce_shuffle,spark_shuffle
yarn.nodemanager.container-executor.class=org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor
yarn.nodemanager.container-manager.thread-count=20
yarn.nodemanager.container-metrics.enable=false
yarn.nodemanager.container-monitor.interval-ms=3000
yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled=false
yarn.nodemanager.delete.debug-delay-sec=3600
yarn.nodemanager.delete.thread-count=4
yarn.nodemanager.disk-health-checker.interval-ms=120000
yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage=98.0
yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb=0
yarn.nodemanager.disk-health-checker.min-healthy-disks=0.25
yarn.nodemanager.docker-container-executor.exec-name=/usr/bin/docker
yarn.nodemanager.env-whitelist=JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,HADOOP_YARN_HOME
yarn.nodemanager.health-checker.interval-ms=600000
yarn.nodemanager.health-checker.script.timeout-ms=1200000
yarn.nodemanager.hostname=0.0.0.0
yarn.nodemanager.keytab=/etc/krb5.keytab
yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms=5000
yarn.nodemanager.linux-container-executor.cgroups.hierarchy=/hadoop-yarn
yarn.nodemanager.linux-container-executor.cgroups.mount=false
yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage=false
yarn.nodemanager.linux-container-executor.group=yarn
yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users=true
yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user=yarn
yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern=^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$
yarn.nodemanager.linux-container-executor.path=/etc/yarn-executor/container-executor
yarn.nodemanager.linux-container-executor.resources-handler.class=org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler
yarn.nodemanager.local-cache.max-files-per-directory=8192
yarn.nodemanager.localizer.cache.cleanup.interval-ms=600000
yarn.nodemanager.localizer.cache.target-size-mb=10240
yarn.nodemanager.localizer.client.thread-count=20
yarn.nodemanager.localizer.fetch.thread-count=100
yarn.nodemanager.log-aggregation.compression-type=none
yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds=-1
yarn.nodemanager.log-dirs=/data0/yarn1/logs,/data1/yarn1/logs,/data2/yarn1/logs,/data3/yarn1/logs,/data4/yarn1/logs,/data5/yarn1/logs,/data6/yarn1/logs,/data7/yarn1/logs,/data8/yarn1/logs,/data9/yarn1/logs,/data10/yarn1/logs,/data11/yarn1/logs
yarn.nodemanager.log.retain-seconds=86400
yarn.nodemanager.pmem-check-enabled=true
yarn.nodemanager.process-kill-wait.ms=2000
yarn.nodemanager.recovery.dir=${hadoop.tmp.dir}/yarn-nm-recovery
yarn.nodemanager.recovery.enabled=false
yarn.nodemanager.remote-app-log-dir-suffix=logs
yarn.nodemanager.remote-app-log-dir=/tmp/app-logs
yarn.nodemanager.resource.cpu-vcores=50
yarn.nodemanager.resource.gcores=0
yarn.nodemanager.resource.memory-mb=204800
yarn.nodemanager.resource.percentage-physical-cpu-limit=85
yarn.nodemanager.resourcemanager.minimum.version=NONE
yarn.nodemanager.sleep-delay-before-sigkill.ms=250
yarn.nodemanager.vmem-check-enabled=false
yarn.nodemanager.vmem-pmem-ratio=3.1
yarn.nodemanager.windows-container.cpu-limit.enabled=false
yarn.nodemanager.windows-container.memory-limit.enabled=false
yarn.resourcemanager.admin.client.thread-count=1
yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs=86400
yarn.resourcemanager.am.max-attempts=5
yarn.resourcemanager.amlauncher.thread-count=50
yarn.resourcemanager.client.thread-count=100
yarn.resourcemanager.cluster-id=cluster1
yarn.resourcemanager.configuration.provider-class=org.apache.hadoop.yarn.LocalConfigurationProvider
yarn.resourcemanager.connect.max-wait.ms=900000
yarn.resourcemanager.connect.retry-interval.ms=30000
yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs=86400
yarn.resourcemanager.container.liveness-monitor.interval-ms=600000
yarn.resourcemanager.delayed.delegation-token.removal-interval-ms=30000
yarn.resourcemanager.fs.state-store.num-retries=0
yarn.resourcemanager.fs.state-store.retry-interval-ms=1000
yarn.resourcemanager.fs.state-store.retry-policy-spec=2000, 500
yarn.resourcemanager.fs.state-store.uri=${hadoop.tmp.dir}/yarn/system/rmstore
yarn.resourcemanager.ha.automatic-failover.embedded=true
yarn.resourcemanager.ha.automatic-failover.enabled=true
yarn.resourcemanager.ha.automatic-failover.zk-base-path=/10k-yarn/yarn-leader-election
yarn.resourcemanager.ha.enabled=true
yarn.resourcemanager.ha.id=rm1
yarn.resourcemanager.ha.rm-ids=rm1,rm2
yarn.resourcemanager.hostname.rm1=BJLFRZ-10k-149-67.hadoop.jd.local
yarn.resourcemanager.hostname.rm2=BJLFRZ-10k-149-68.hadoop.jd.local
yarn.resourcemanager.hostname=0.0.0.0
yarn.resourcemanager.keytab=/etc/krb5.keytab
yarn.resourcemanager.leveldb-state-store.path=${hadoop.tmp.dir}/yarn/system/rmstore
yarn.resourcemanager.max-completed-applications=20000
yarn.resourcemanager.nodemanager-connect-retries=10
yarn.resourcemanager.nodemanager.minimum.version=NONE
yarn.resourcemanager.nodemanagers.heartbeat-interval-ms=1000
yarn.resourcemanager.nodes.exclude-path=/software/servers/hadoop-2.7.1/etc/hadoop/hosts/exclude_mapred_hosts
yarn.resourcemanager.nodes.include-path=/software/servers/hadoop-2.7.1/etc/hadoop/hosts/mapred_hosts
yarn.resourcemanager.proxy-user-privileges.enabled=false
yarn.resourcemanager.recovery.enabled=true
yarn.resourcemanager.resource-tracker.client.thread-count=50
yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.hydra.HydraScheduler
yarn.resourcemanager.scheduler.client.thread-count=200
yarn.resourcemanager.scheduler.monitor.enable=false
yarn.resourcemanager.scheduler.monitor.policies=org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy
yarn.resourcemanager.scheduler.node.comparator=false
yarn.resourcemanager.state-store.max-completed-applications=3000
yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.JDRMStateStore
yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size=10
yarn.resourcemanager.system-metrics-publisher.enabled=false
yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled=true
yarn.resourcemanager.work-preserving-recovery.enabled=true
yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms=10000
yarn.resourcemanager.zk-num-retries=1000
yarn.resourcemanager.zk-retry-interval-ms=1000
yarn.resourcemanager.zk-state-store.parent-path=/10k-yarn/rmstore
yarn.resourcemanager.zk-timeout-ms=60000
yarn.router.clientrm.interceptor-class.pipeline=org.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor
yarn.router.pipeline.cache-max-size=25
yarn.router.rmadmin.interceptor-class.pipeline=org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor
yarn.scheduler.busy.node.filter.indicator=cpu
yarn.scheduler.busy.node.filter.limit=10
yarn.scheduler.busy.node.filter.splitscale=0.70
yarn.scheduler.fair.allocation.file=/software/servers/hadoop-2.7.1/etc/hadoop/fair-scheduler.xml
yarn.scheduler.fair.allow-undeclared-pools=false
yarn.scheduler.fair.assignmultiple=true
yarn.scheduler.fair.continuous-scheduling-enabled=false
yarn.scheduler.fair.is-reserve=false
yarn.scheduler.fair.locality-delay-node-ms=-1
yarn.scheduler.fair.locality-delay-rack-ms=-1
yarn.scheduler.fair.locality.threshold.node=0.1
yarn.scheduler.fair.locality.threshold.rack=0.1
yarn.scheduler.fair.max.assign=5
yarn.scheduler.fair.schedule-asynchronously.enable=true
yarn.scheduler.fair.schedule-asynchronously.max-pending-backlogs=1000
yarn.scheduler.fair.schedule-asynchronously.maximum-threads=20
yarn.scheduler.fair.update-interval-ms=60
yarn.scheduler.increment-allocation-mb=1024
yarn.scheduler.maximum-allocation-gcores=2
yarn.scheduler.maximum-allocation-mb=53248
yarn.scheduler.maximum-allocation-vcores=50
yarn.scheduler.minimum-allocation-gcores=0
yarn.scheduler.minimum-allocation-mb=512
yarn.scheduler.minimum-allocation-vcores=1
yarn.scheduler.util.statistics.cpu.weight=1
yarn.scheduler.util.statistics.disk.weight=1
yarn.scheduler.util.statistics.highload.threshold=0.50
yarn.scheduler.util.statistics.mem.weight=1
yarn.scheduler.util.statistics.net.weight=1
yarn.sharedcache.admin.thread-count=1
yarn.sharedcache.app-checker.class=org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker
yarn.sharedcache.checksum.algo.impl=org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl
yarn.sharedcache.cleaner.initial-delay-mins=10
yarn.sharedcache.cleaner.period-mins=1440
yarn.sharedcache.cleaner.resource-sleep-ms=0
yarn.sharedcache.client-server.thread-count=50
yarn.sharedcache.enabled=false
yarn.sharedcache.nested-level=3
yarn.sharedcache.nm.uploader.replication.factor=10
yarn.sharedcache.nm.uploader.thread-count=20
yarn.sharedcache.root-dir=/sharedcache
yarn.sharedcache.store.class=org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore
yarn.sharedcache.store.in-memory.check-period-mins=720
yarn.sharedcache.store.in-memory.initial-delay-mins=10
yarn.sharedcache.store.in-memory.staleness-period-mins=10080
yarn.sharedcache.uploader.server.thread-count=50
yarn.timeline-service.client.best-effort=false
yarn.timeline-service.client.max-retries=30
yarn.timeline-service.client.retry-interval-ms=1000
yarn.timeline-service.enabled=false
yarn.timeline-service.handler-thread-count=10
yarn.timeline-service.hostname=0.0.0.0
yarn.timeline-service.http-authentication.simple.anonymous.allowed=true
yarn.timeline-service.http-authentication.type=simple
yarn.timeline-service.keytab=/etc/krb5.keytab
yarn.timeline-service.leveldb-state-store.path=${hadoop.tmp.dir}/yarn/timeline
yarn.timeline-service.leveldb-timeline-store.path=${hadoop.tmp.dir}/yarn/timeline
yarn.timeline-service.leveldb-timeline-store.read-cache-size=104857600
yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size=10000
yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size=10000
yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms=300000
yarn.timeline-service.recovery.enabled=false
yarn.timeline-service.state-store-class=org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore
yarn.timeline-service.store-class=org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore
yarn.timeline-service.ttl-enable=true
yarn.timeline-service.ttl-ms=604800000
zookeeper.znode.parent=/hbase_triton
